{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6ee64a",
   "metadata": {},
   "source": [
    "# MoneyMakingAlgorithm (MMA) Light — Guide\n",
    "\n",
    "This projects aims at \n",
    "\n",
    "This notebook walks through the entire data pipeline from (from raw data to predictions) for predicting the win method of fights in the upcoming Ultimate Bouting Championship (UFC) event, a weekly or every-other-weekly Mixed Martial Arts (MMA) tournament.\n",
    "\n",
    "Highlights: \n",
    "- Retrieves raw data, cleans raw data, engineers features, trains a model and makes predictions for upcoming Ultimate Fighting Championship (UFC) fights. \n",
    "- Predicts 7 classes: KO win, Submission win, Decision win, Draw, Decision Loss, Submission Loss, KO loss. \n",
    "- Creates probability distributions for each of the 7 classes that can then be used for price estimation and risk analysis\n",
    "- Makes predictions using a self-devised elo-based rating system and other features. \n",
    "- Machine Learning method used: Extreme Gradient Booster (`xgboost`)\n",
    "- Trains the model using a repeated m-fold cross validation.\n",
    "- Includes singular value decomposition, feature selection and other optional data processing features.\n",
    "- Outputs the statistics of predicted probability distributions for both 7 and 2 (win or lose) classes. \n",
    "\n",
    "Notes\n",
    "This is a light version and has certain feature sets left out compared to the full model. As such, it will be considerably less accurate. In addition, the data cleaning module (Section 1) is disabled. You can still use this notebook to play around and make your own predictions with.\n",
    "\n",
    "DISCLAIMER \n",
    "- This is not to be used for gambling! The purpose of this project is to obtain statistics for price estimation and risk analysis. If this model does what it should, it would tell you sportsbook offer unfavorable prices!\n",
    "\n",
    "\n",
    "## Quick setup (Windows/PowerShell)\n",
    "\n",
    "```powershell\n",
    "# From the repo root (this folder)\n",
    "py -3.11 -m venv .venv\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# If xgboost-cpu wheel fails on your CPU, try:\n",
    "# pip install xgboost==2.1.1\n",
    "```\n",
    "\n",
    "In VS Code, select the `.venv` interpreter for the notebook: Ctrl+Shift+P → “Python: Select Interpreter” → choose `.venv`.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Cleaning Data\n",
    "\n",
    "Raw ufcstats.com datasets are loaded from Greco1899's scape_ufc_stats repository. These datasets are regularly updated by the corresponding scraper (https://github.com/Greco1899/scrape_ufc_stats). Second, datasets are cleaned and merged into a single data set with basic features are created (date, height, time format etc...) and made ready for further feature engineering. Output csv is saved as `data/interim/clean_ufcstats-com_data.csv`.\n",
    "\n",
    "Key module: `src/data_processing/clean_raw_data.py`\n",
    "- Main function: `process_all_data(prefer_external=True, new_fights_only=False)`\n",
    "- Core class: `UFCDataProcessor`\n",
    "\n",
    "Notes:\n",
    "- Only events from UFC 31: Locked and Loaded (May 04, 2001) are included, because this is the first standardized UFC event (using the Unified Rules of MMA and has only 3 or 5 round fights. \n",
    "- Set `new_fights_only=False` (WIP otherwise).\n",
    "- `prefer_external` takes from external github repository (regularly updated) and otherwise from saved data.\n",
    "- Not all names in ufc_fight_results.csv match with those in ufc_fighter_tott. In addition, some fighters in ufc_fighter_tott have the same name, or are mentioned double with (one with stats, the other without etc). These issues have been resolved for all retired and currently active fighters, but may arise again in the future for newly debuting fighters. In this case, the code terminates and user must follow the instructions in the log and comments to implement a simple hard-code fix. \n",
    "- If there will ever be a Catch Weight bout where both fighters are debuting, sex cannot be inferred. Code termination for manual appending sex to 'interim/unknown_sex.csv'. One could also implement a AI that recognizes male/female names to solve this.   \n",
    "\n",
    "Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421447b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 01:24:05.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mprocess_all_data\u001b[0m:\u001b[36m706\u001b[0m - \u001b[1mStarting UFC data processing pipeline\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:05.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mInitialized UFC data processor\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:05.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36m_run_data_processing\u001b[0m:\u001b[36m741\u001b[0m - \u001b[1mLoading raw data\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:05.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSuccesfully loaded data from https://github.com/Greco1899/scrape_ufc_stats\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:05.746\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\raw\\ufc_event_details.csv (748 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:06.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSuccesfully loaded data from https://github.com/Greco1899/scrape_ufc_stats\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:06.237\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\raw\\ufc_fight_results.csv (8377 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSuccesfully loaded data from https://github.com/Greco1899/scrape_ufc_stats\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\raw\\ufc_fight_stats.csv (39422 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mload_raw_data\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mSuccesfully loaded data from https://github.com/Greco1899/scrape_ufc_stats\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.883\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\raw\\ufc_fighter_tott.csv (4447 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.909\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\interim\\alternative_spellings_internal.csv (59 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36m_run_data_processing\u001b[0m:\u001b[36m751\u001b[0m - \u001b[1mStarting data cleaning.\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mCleaning fight results data\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:07.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m141\u001b[0m - \u001b[1mPreparing raw data sets...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:08.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m173\u001b[0m - \u001b[1mMatching bouts and fighters...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:08.094\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mProcessing duplicate names...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:08.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mProcessing temporal data...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:08.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m454\u001b[0m - \u001b[1mGetting fighter specific info...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:24:08.771\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m559\u001b[0m - \u001b[1mProcessing fight stats...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:25:07.947\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\interim\\ufc_fighter_tott_clean.csv (4443 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:25:07.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m663\u001b[0m - \u001b[1mCreating classes...\u001b[0m\n",
      "\u001b[32m2025-10-10 01:25:08.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36mclean_data\u001b[0m:\u001b[36m691\u001b[0m - \u001b[1mFINITOOOOOOOOOOO\u001b[0m\n",
      "\u001b[32m2025-10-10 01:25:08.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36m_run_data_processing\u001b[0m:\u001b[36m760\u001b[0m - \u001b[1mStoring cleaned data\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-10 01:25:13.186\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma_light\\data\\interim\\clean_ufcstats-com_data.csv (8102 rows)\u001b[0m\n",
      "\u001b[32m2025-10-10 01:25:13.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.clean_raw_data\u001b[0m:\u001b[36m_run_data_processing\u001b[0m:\u001b[36m808\u001b[0m - \u001b[1mUFC data processing pipeline completed successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Disabled in light version\n",
    "#from src.data_processing.clean_raw_data import process_all_data\n",
    "\n",
    "\n",
    "#process_all_data(prefer_external=True, new_fights_only=False)\n",
    "# Expected: data/interim/clean_ufcstats-com_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4c680",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Constructing feature sets\n",
    "\n",
    "+ We now construct both our desired feature sets, and the feature sets they depend on. \n",
    "\n",
    "Key module: `src/data_processing/feature_manager.py`\n",
    "- Class: `FeatureManager(feature_set_names=None, feature_set_params=None, overwrite_all=True)`\n",
    "- Feature modules live in `src/feature_engineering` and are imported dynamically (e.g., `get_base_features.py`).\n",
    "\n",
    "Available feature sets:\n",
    "- base_features (always include)\n",
    "- elo_params (always include for elo feature set)\n",
    "- wl_elos\n",
    "\n",
    "\n",
    "Regarding elo_params \n",
    "- get_elo_params creates multiple K-parameters which can then be chosen by the elo feature set using 'which_K'.\n",
    "\n",
    "\n",
    "Notes:\n",
    "- Keep the param `process_upcoming_fights=False` at this stage (otherwise handled separately).\n",
    "Python (corrected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e000b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 03:33:22.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\base_features.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:22.050\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\elo_params.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:22.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\wl_elos.csv (8114 rows)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.data_processing.feature_manager.FeatureManager at 0x12bfaddb0e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_processing.feature_manager import FeatureManager\n",
    "from src.feature_engineering.get_elo_params import set_elo_params\n",
    "\n",
    "feature_sets = {}\n",
    "\n",
    "# Parameters per feature module\n",
    "base_features_params = {}\n",
    "elo_params = {\"d_params\": set_elo_params()}  # provide Elo parameters\n",
    "wl_elos_params = {\"which_K\": \"log\"}\n",
    "\n",
    "# Choose final feature sets\n",
    "feature_sets[\"base_features\"] = base_features_params\n",
    "feature_sets[\"elo_params\"] = elo_params\n",
    "feature_sets[\"wl_elos\"] = wl_elos_params\n",
    "\n",
    "# Create feature sets (writes CSVs under data/features/)\n",
    "# overwrite_all = True disabled in light version. \n",
    "FeatureManager(feature_sets, overwrite_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecd61f",
   "metadata": {},
   "source": [
    "Expected outputs under `data/features/`: one CSV per enabled set, e.g., `base_features.csv`, `elo_params.csv`, `wl_elos.csv`, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Creating training set, validation set and data-to-predict (TrainValPred) and further processing\n",
    "\n",
    "+ Key module: `src/model_selection/trainvalpred.py`\n",
    "- Class: `TrainValPred(feature_sets=None)`\n",
    "\n",
    "### 3.1 Creating the training and validation data\n",
    "+ Training data is created by merging feature sets and splitting off the validation data  \n",
    "+ To validate the model on relevant data, we split the validation set based on recency, either by \n",
    "last `last_years` years, or the most recent `sample_size` (proportion) of the data. The value that represents the smallest portion of the data takes precedence! When based `sample_size`, you can choose to randomly sample them from the last `last_years` of fights by setting `if_on_size_then_randomly=True` (Default False). \n",
    "+ When   \n",
    "+ The snippet below creates files `interim/chosen_features_merged`, `processed/train.csv` and `procssed/valid.csv`, +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6911458f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 03:33:26.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_selection.trainvalpred\u001b[0m:\u001b[36mmerge_features\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mMerging features...\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\base_features.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\elo_params.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\features\\wl_elos.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.830\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\interim\\chosen_features_merged.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_selection.trainvalpred\u001b[0m:\u001b[36m_do_merge_features\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mFeatures merged.\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:26.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.data_processing.feature_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mOpening merged feature set\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.052\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\interim\\chosen_features_merged.csv (8114 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.059\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mcreaopen_file\u001b[0m:\u001b[36m179\u001b[0m - \u001b[34m\u001b[1mFile doesn't exist, returning empty DataFrame: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\interim\\pred_clean\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model_selection.trainvalpred\u001b[0m:\u001b[36m_do_split_trainval\u001b[0m:\u001b[36m363\u001b[0m - \u001b[1mValidation set contains last 1.6 years of fights, representing 10% of data.\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\interim\\valid_names.csv (1602 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.185\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\interim\\train_names.csv (14410 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\train.csv (14410 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:33:27.937\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\valid.csv (1602 rows)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.model_selection.trainvalpred import TrainValPred\n",
    "\n",
    "TVP = TrainValPred(feature_sets)\n",
    "\n",
    "# Merge all selected feature sets\n",
    "TVP.merge_features(overwrite_feature_sets=False)\n",
    "\n",
    "# Choose validation partition (recent years and sample fraction; smallest takes precedence)\n",
    "last_years = 3\n",
    "sample_size = 0.1\n",
    "\n",
    "TVP.split_trainval(last_years=last_years, \n",
    "                   sample_size=sample_size, \n",
    "                   if_on_size_then_randomly = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14635de",
   "metadata": {},
   "source": [
    "Expected outputs:\n",
    "- `data/interim/chosen_features_merged.csv`\n",
    "- `data/processed/train.csv`\n",
    "- `data/processed/valid.csv`\n",
    "- `data/interim/train_names.csv` and `data/interim/valid_names.csv`\n",
    "\n",
    "### 3.2 Scraping, cleaning and processing features for data-to-predict. \n",
    "\n",
    "- The snippet below runs the entire prediction data pipeline from scraping `ufcstats.com`'s upcoming event data to creating all the features. \n",
    "- Creates files: `raw/pred_raw.csv`, `interim/pred_clean`, `processed/pred.csv`, +1\n",
    "- Tip: rerun this snippet if any bouts get cancelled/replaced.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3f8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.scrape_pred import scrape_pred\n",
    "from src.data_processing.clean_pred import clean_pred\n",
    "\n",
    "# Disabled in light version. Will be uploaded separately.\n",
    "#TVP.construct_pred(scrape_and_clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cd607",
   "metadata": {},
   "source": [
    "Expected outputs:\n",
    "- `data/raw/pred_raw.csv`\n",
    "- `data/interim/pred_clean.csv`\n",
    "- `data/processed/pred.csv`\n",
    "- `data/interim/pred_names.csv`\n",
    "```\n",
    "\n",
    "### 3.3 Optional further feature processing\n",
    "\n",
    "There are now basically three options: \n",
    "1. No further processing and go straight to training (`suffix = \"natty\"`) \n",
    "2. Make (anti-)symmetric features, i.e. `fighter1_feautures -> (fighter1_features + fighter2_features)/sqrt(2)` and  `fighter2_feautures -> (fighter1_features - fighter2_features)/sqrt(2)`, and leave shared features be. In this case, set `suffix = \"symm\"`. \n",
    "3. Do a Singular Value Decompostion(SVD) on the data `suffix = \"svd\"` and transform to the Schmidt basis. \n",
    "\n",
    "Notes \n",
    "- The SVD path first standardizes the data and also makes (anti-)symmetric pairs. However, in contrast to `symmetrize(for_svd = False)`, one-hot encoded features will not be transformed to flags. This is done because one-hot encoded features could be favorable for the SVD, but otherwise waste xgb splits. \n",
    "- Ceates datasets `processed/train_{suffix}`, `processed/valid_{suffix}`, `processed/pred_{suffix}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbd2a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-14 03:46:27.562\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\train.csv (14410 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:46:27.582\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\valid.csv (1602 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:46:27.592\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mopen_csv\u001b[0m:\u001b[36m118\u001b[0m - \u001b[34m\u001b[1mLoaded CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\pred.csv (26 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:46:28.235\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\train_natty.csv (14410 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:46:28.304\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\valid_natty.csv (1602 rows)\u001b[0m\n",
      "\u001b[32m2025-10-14 03:46:28.315\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.utils.general\u001b[0m:\u001b[36mstore_csv\u001b[0m:\u001b[36m155\u001b[0m - \u001b[34m\u001b[1mSaved CSV: c:\\Users\\OAVAI\\Desktop\\mma - Copy\\mma_light\\data\\processed\\pred_natty.csv (26 rows)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "suffix = 'natty' # 'symm', 'svd', or 'natty'\n",
    "\n",
    "if suffix == 'symm': \n",
    "    TVP.symmetrize(for_svd = False) \n",
    "\n",
    "elif suffix == 'svd':\n",
    "    # Because you probably wanna check where you truncate,\n",
    "    # you may have to run the SVD twice. \n",
    "    # TVP.svd(k = 10e6, plot_sv = True)\n",
    "    \n",
    "    TVP.do_svd(k=204)  \n",
    "elif suffix == 'natty': \n",
    "    TVP.go_natty() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training and predictions\n",
    "\n",
    "### 4.1 Hyperparameter optimization (Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'symm'\n",
    "CV = CrossValidationMain('symm') \n",
    "\n",
    "# Optionally, change default parameters (at any point in the pipeline)\n",
    "valid_params = { \n",
    "    'vv_size': 0, \n",
    "    'vv_seed': 34, \n",
    "    'vv_random_split': False\n",
    "}\n",
    "cv_params = { \n",
    "    'n_repeats': 3,\n",
    "    'n_folds': 5, \n",
    "    'fold_seed': 42\n",
    "} \n",
    "# Chose either tuple or fixed value \n",
    "hyper_params = { \n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": (0.02, 0.025),\n",
    "    \"n_estimators\": (400,600),\n",
    "    \"min_child_weight\": (0, 40),\n",
    "    \"gamma\": (0, 2.5),\n",
    "    \"subsample\": (0.7, 0.85),\n",
    "    \"colsample_bytree\": 1,\n",
    "    # Optional regularization\n",
    "    \"reg_alpha\": 0.0,\n",
    "    \"reg_lambda\": 1.0\n",
    "}\n",
    "CV.set_valid_params(valid_params) \n",
    "CV.set_cv_params(cv_params)\n",
    "CV.set_hyper_params(hyper_params)\n",
    "\n",
    "# Initial training \n",
    "CV.optimize(n_trials = 50) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature selection and re-training \n",
    "\n",
    "+ The following code snippet automatically selects the best hyperparameters from the output metrics file and starts feature selection. It outputs file `output/feature_selection/feature_frequency`.\n",
    "+ After ranking all features by their importance and counting how many times they it starts optimizing hyperparameters again but this time also varying over a range of the k_selected-th most important features.\n",
    "+ Because during HPO xgb random_state is fixed, we can set `rndstate_stability_check=True` to measure the stability of the model over different seeds. It will take the `top_n` parameter combinations with the best metrics and does `n_repeats` of cross validation, where inside each fold a different random seed is chosen. The seeds-averaged metrics will be stored in `data/output/metrics/{suffix}_stability_check.csv` and the best ones are automatically retrieved for further feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, change default stability check params \n",
    "stability_check_params = {\n",
    "    'top_n': 1, \n",
    "    'n_repeats': 2\n",
    "}\n",
    "CV.set_stability_check_params(stability_check_params)\n",
    "\n",
    "CV.select_features(rnd_state_stability_check = True)\n",
    "\n",
    "select_by = 'frequency'   # or by index \n",
    "\n",
    "if select_by == 'frequency': \n",
    "    max_freq = CV.cv_params['n_repeats'] * CV.cv_params['n_folds'] \n",
    "    feature_range = (max_freq-2, max_freq)\n",
    "elif select_by == 'index': \n",
    "    max_index = len(CV.Xt.columns)\n",
    "    feature_range = (50, max_index - 50) \n",
    "CV.set_feature_params(\n",
    "    select_by = select_by, \n",
    "    feature_range = feature_range\n",
    ") \n",
    "\n",
    "CV.optimize(n_trials = 30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Making predictions\n",
    "\n",
    "+ Now we can start making predictions. Program automatically selects the best hyperparameters and the best k_selected most important columns and calculates probabilities for each of the 7 classes.\n",
    "+ The output file `output/predictions/pred_{suffix}` contains averages, standard deviations, mean +/- 2std, 5perc, 95perc, min max for each of the 7 classes. These values define the probability distributions that are created by making predictions in each of the folds of the n_repeats unique 5-folds (so `n_repeats*n_folds` unique samples).  \n",
    "+ In contrast to training, for each repeat and for each fold, a different xgb random state is chosen. \n",
    "+ Probability distributions are created for both 7 classes and 2 classes (win or lose). In case of two classes, a draw basically means money back so win probabilities are calculated as $$P_{win} = \\frac{P_{KO} + P_{Sub} + P_{Dec}}{1-P_{Draw}}$$\n",
    "+ Based on the validation set, the model also creates a plot to show how well it's calibrated.\n",
    "+ Also makes predictions for debuting fighters, but the model does not take into account previous carreer stats. This means that, with luck, only height, reach and age are available. Take this into account when competing against other models and comparing accuracies. \n",
    "+ In stead of using the model parameters with the best metrics from the previous optimization step, you can also first do a rndstate_stability_check again and use the best paramaters of those.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.change_param(n_repeats = 200) # Takes n_repeats * n_folds samples with as many different random states\n",
    "CV.predict(rndstate_stability_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run in your browser (GitHub Codespaces)\n",
    "\n",
    "Run the notebook and view MLflow entirely in the browser using GitHub Codespaces.\n",
    "\n",
    "[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/REPLACE_WITH_YOUR_GITHUB_USERNAME_OR_ORG/REPO_NAME?quickstart=1)\n",
    "\n",
    "What it does\n",
    "- Spins up a cloud dev environment with Python 3.11\n",
    "- Auto-installs `requirements.txt` (devcontainer provided)\n",
    "- Forwards MLflow UI on port 5000\n",
    "\n",
    "Steps\n",
    "1) Click the badge above (or Code → Codespaces → Create codespace on main)\n",
    "2) Open `mma_project_guide.ipynb` and run cells\n",
    "3) To view MLflow UI, open a terminal and run:\n",
    "\n",
    "```bash\n",
    "mlflow ui --host 0.0.0.0 --port 5000\n",
    "```\n",
    "\n",
    "The port will auto-forward; click the globe icon in the Ports panel to open the UI in a new tab.\n",
    "# mma_money_making_algorithm\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledements \n",
    "\n",
    "Massive thanks to Erik Prjadka for his invaluable advice throughout, teaching me about data science principles and which machine learning method to use. Also to Sjoerd Visser for bringing me up to date on machine learning and coding standards and practices. \n",
    "\n",
    "## Sources \n",
    "- www.ufcstats.com\n",
    "- greco1899/ufc_stats_scraper\n",
    "- pandas\n",
    "- xgboost \n",
    "- numpy \n",
    "- sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
